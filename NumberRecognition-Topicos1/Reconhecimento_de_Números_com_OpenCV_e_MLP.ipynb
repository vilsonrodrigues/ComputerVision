{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reconhecimento de Números com OpenCV e MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vilsonrodrigues/ComputerVision/blob/master/NumberRecognition-Topicos1/Reconhecimento_de_N%C3%BAmeros_com_OpenCV_e_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ajifzwdvgNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39c4SQWT1nez",
        "colab_type": "text"
      },
      "source": [
        "Descompactando um arquivo Zip "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azBVb8I3x45b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip numeros.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KloedpWEGD32",
        "colab_type": "text"
      },
      "source": [
        "Função para separar as imagens e os labels delas correspondentes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZubAR1tIvvHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = []\n",
        "labels = []\n",
        "def traverse_dir(path):\n",
        "    for file_or_dir in os.listdir(path):\n",
        "        abs_path = os.path.abspath(os.path.join(path, file_or_dir))\n",
        "        print(abs_path)\n",
        "        if os.path.isdir(abs_path):  # dir\n",
        "            traverse_dir(abs_path)\n",
        "        else:                        # file\n",
        "            if file_or_dir.endswith('.jpg'):\n",
        "                image = read_image(abs_path)\n",
        "                images.append(image)\n",
        "                labels.append(path[len(path)-1])\n",
        "\n",
        "    return images, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC1EtPqCG6EP",
        "colab_type": "text"
      },
      "source": [
        "Função para converter em tons de cinza e depois inverter a cor a fim de facilitar a identificação dos caracteres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e17P3HgAv0ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_image(file_path):\n",
        "    image = cv2.imread(file_path)\n",
        "    # converte para tons de cinza \n",
        "    gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # inverte a cor \n",
        "    image = cv2.bitwise_not(gray_scale) \n",
        "    return image\n",
        "\n",
        "\n",
        "def extract_data(path):\n",
        "    images, labels = traverse_dir(path)\n",
        "    images = np.array(images)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cboYE-JiHve8",
        "colab_type": "text"
      },
      "source": [
        "Extraindo da pasta e depois aplicando reshape nas labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APCmjrkmwM3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = extract_data('./numeros/')\n",
        "labels = np.reshape(labels, [-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkxvxvyDVEVN",
        "colab_type": "text"
      },
      "source": [
        "Teste para verificar a imagem e o seu alvo (o número no caso)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ltbcBByaAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "e7f657a9-1ffb-4d1d-e087-f5209a07496e"
      },
      "source": [
        "print('Images shape:', images.shape)\n",
        "print('Labels shape:', labels.shape)\n",
        "\n",
        "plt.imshow(images[11],cmap=plt.get_cmap(\"gray\") )\n",
        "\n",
        "print(labels[11])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images shape: (1170, 28, 32)\n",
            "Labels shape: (1170,)\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAD4CAYAAAAzSCmHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdCfgzg1H4-G",
        "colab_type": "text"
      },
      "source": [
        "Codificação de Rótulos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDwZk0m6uLtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3613c3e5-3a87-4fc8-df9a-eb20dafaa7cf"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labels)\n",
        "list(le.classes_)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTCK0rVgvQFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90b2b2f1-43e2-4275-804d-3d3e2b79ecf6"
      },
      "source": [
        "labels "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '1', '1', ..., '3', '3', '3'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA794iCuv-Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_enc = le.transform(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9es0iQZ0wIUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d3d242ac-5626-48da-bfb1-a7f0cebd1d12"
      },
      "source": [
        "print(labels_enc[0])\n",
        "print(labels[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRfZlCLdDQ01",
        "colab_type": "text"
      },
      "source": [
        "Separando o conjunto em treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgvgRyLXyVYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.25, random_state = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG-ZIICrmSON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28*32) \n",
        "X_test = X_test.reshape(X_test.shape[0], 28*32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vweb5TFqp4sF",
        "colab_type": "code",
        "outputId": "8574451f-40df-4774-d59e-53ccc051b401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(877, 896)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKVlPB41C7NT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8275515d-615c-41aa-8057-a6c5c3d8bb6e"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
              "         0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0, 255,   0,   0,   0,   0,   0,   0,\n",
              "         0,   1,   1,   0,   0,   0,   0,   2,   0,   0,   3,   0,   0,\n",
              "         2,   2,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0, 255,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   0,   0,   0,\n",
              "         0,   2,   1,   2,   0,   0,   1,   0,   0,   1,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0, 255,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   4,   0,   0,   1,   0,   0,   2,   3,   0,\n",
              "         4,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   1,   3,   0,   1,   0,   2,\n",
              "         0,   2, 254, 255, 252,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0, 255,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "         1,   0,   0,   0, 255, 254, 255, 255, 251, 255, 255, 254,   0,\n",
              "         0,   2,   0,   0,   0,   0,   0,   0,   0,   0, 255,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   4,   1, 255, 255, 252,   0,\n",
              "         0,   4,   0,   0, 255, 255, 254,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0, 255,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
              "         0,   0, 255, 255,   0,   1,   1,   0,   3,   1,   0, 255, 255,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0, 255,   0,   0,   0,\n",
              "         0,   0,   0,   0,   1,   0,   1, 255, 254,   0,   2,   0,   1,\n",
              "         0,   0,   1,   0, 255, 254, 255,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0, 254,\n",
              "       255, 255,   0,   2,   0,   0,   0,   0,   4,   0, 253, 255, 255,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0, 255,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   5,   0, 253, 255, 253, 253, 255, 255, 251,\n",
              "       255, 254, 251, 255, 255, 255,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,\n",
              "       255, 255, 255, 254, 253, 255, 254, 255, 255, 255, 252,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 255,   0,   0,   0,   0,   0,\n",
              "         0,   0,   3,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
              "         0, 255, 255, 255,   3,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,   0,\n",
              "         2,   0,   1,   0,   3,   1,   0, 254, 255,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0, 255,   0,   0,   0,   0,   0,   0,\n",
              "         0,   1,   0,   0,   3,   2,   0,   1,   0,   0,   0,   0, 254,\n",
              "       255, 254,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   1,\n",
              "         0,   2,   0,   1,   0, 255, 251, 255,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0, 255,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   1,   0,   0,   2, 255,   0,   1,   0, 255, 255, 252,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   3,   0, 254,\n",
              "         0,   0, 254, 253, 254,   0,   4,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0, 255,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         0,   1,   0,   0,   0,   3,   1, 255, 255, 255,   2,   1,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0, 255,   1,   0,   0,   2,   0, 255,\n",
              "       255, 254,   0,   0,   0,   4,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0, 255,   0,   0,   0,   0,   0,   0,   0,   0, 254,\n",
              "       254, 255,   0,   0, 255, 255, 254,   1,   0,   1,   1,   0,   1,\n",
              "         1,   0,   0,   0,   0,   0,   0,   0,   0, 255,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0, 255, 254, 255, 255, 255, 255, 253,   0,\n",
              "         0,   0,   4,   0,   1,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0, 255,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n",
              "         0, 252, 255,   0,   2,   3,   0,   2,   0,   2,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0, 255,   0,   0,   0,   0,\n",
              "         0,   0,   0,   1,   0,   4,   0,   1,   0,   0,   1,   0,   3,\n",
              "         0,   2,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0, 255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 255,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       255,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0, 255,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "      dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSeOg0JQ29Z7",
        "colab_type": "text"
      },
      "source": [
        "Aplicando uma redução de dimensionaldidade aos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZqwHlHCCgyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keG1jwB5-hCO",
        "colab_type": "text"
      },
      "source": [
        "Transformando os números em vetor de características"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaSKzIj5vquy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWjYwO_0NkV2",
        "colab_type": "text"
      },
      "source": [
        "Mantendo o Y para saber o alvo ao final do treino e o test e train são transformados em vetores de características de tamanho 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cm24XnqvPZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train,10)\n",
        "y_valid = y_test\n",
        "y_test = to_categorical(y_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sun88CVCN0H4",
        "colab_type": "text"
      },
      "source": [
        "Importando a biblioteca Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_rAGg4NejcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWz_50OjYIBJ",
        "colab_type": "text"
      },
      "source": [
        "Inicializando um modelo do tipo Sequencial e montando a estrutura da MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTE1iL_relZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "# Adding the input layer and the first hidden layer\n",
        "model.add(Dense( activation = 'relu', input_dim = (28*32), units = 50, kernel_initializer = 'uniform'))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "model.add(Dense( activation = 'relu', units = 100, kernel_initializer = 'uniform' ))\n",
        "\n",
        "# Adding the output layer\n",
        "model.add(Dense( activation = 'sigmoid', units = 10, kernel_initializer = 'uniform'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJOtnweqYRKE",
        "colab_type": "text"
      },
      "source": [
        "Compilador a MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxR_gEnIezZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the ANN\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSRwA7ptY2w5",
        "colab_type": "text"
      },
      "source": [
        "Treinando a rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrQqD8UPfFAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5375c4b7-a175-437d-ad15-9d067d72e3d2"
      },
      "source": [
        "history = model.fit(X_train, y_train,validation_split=0.1, batch_size = 10, epochs = 800)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 789 samples, validate on 88 samples\n",
            "Epoch 1/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 4.1569e-05 - acc: 1.0000 - val_loss: 0.6766 - val_acc: 0.9080\n",
            "Epoch 2/800\n",
            "789/789 [==============================] - 0s 215us/step - loss: 3.9261e-05 - acc: 1.0000 - val_loss: 0.6822 - val_acc: 0.9080\n",
            "Epoch 3/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 3.7386e-05 - acc: 1.0000 - val_loss: 0.6842 - val_acc: 0.9068\n",
            "Epoch 4/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 3.5284e-05 - acc: 1.0000 - val_loss: 0.6867 - val_acc: 0.9080\n",
            "Epoch 5/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 3.3722e-05 - acc: 1.0000 - val_loss: 0.6854 - val_acc: 0.9080\n",
            "Epoch 6/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 3.1837e-05 - acc: 1.0000 - val_loss: 0.6900 - val_acc: 0.9057\n",
            "Epoch 7/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 3.0140e-05 - acc: 1.0000 - val_loss: 0.6883 - val_acc: 0.9091\n",
            "Epoch 8/800\n",
            "789/789 [==============================] - 0s 170us/step - loss: 2.8646e-05 - acc: 1.0000 - val_loss: 0.6950 - val_acc: 0.9068\n",
            "Epoch 9/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 2.7269e-05 - acc: 1.0000 - val_loss: 0.6965 - val_acc: 0.9080\n",
            "Epoch 10/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 2.5860e-05 - acc: 1.0000 - val_loss: 0.6963 - val_acc: 0.9080\n",
            "Epoch 11/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 2.4581e-05 - acc: 1.0000 - val_loss: 0.7019 - val_acc: 0.9068\n",
            "Epoch 12/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 2.3421e-05 - acc: 1.0000 - val_loss: 0.7015 - val_acc: 0.9080\n",
            "Epoch 13/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 2.2218e-05 - acc: 1.0000 - val_loss: 0.7036 - val_acc: 0.9080\n",
            "Epoch 14/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 2.1039e-05 - acc: 1.0000 - val_loss: 0.7067 - val_acc: 0.9068\n",
            "Epoch 15/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 2.0083e-05 - acc: 1.0000 - val_loss: 0.7114 - val_acc: 0.9045\n",
            "Epoch 16/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.9095e-05 - acc: 1.0000 - val_loss: 0.7115 - val_acc: 0.9068\n",
            "Epoch 17/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.8156e-05 - acc: 1.0000 - val_loss: 0.7136 - val_acc: 0.9068\n",
            "Epoch 18/800\n",
            "789/789 [==============================] - 0s 168us/step - loss: 1.7298e-05 - acc: 1.0000 - val_loss: 0.7173 - val_acc: 0.9057\n",
            "Epoch 19/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.6532e-05 - acc: 1.0000 - val_loss: 0.7177 - val_acc: 0.9068\n",
            "Epoch 20/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.5682e-05 - acc: 1.0000 - val_loss: 0.7187 - val_acc: 0.9080\n",
            "Epoch 21/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.4946e-05 - acc: 1.0000 - val_loss: 0.7219 - val_acc: 0.9068\n",
            "Epoch 22/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.4179e-05 - acc: 1.0000 - val_loss: 0.7231 - val_acc: 0.9057\n",
            "Epoch 23/800\n",
            "789/789 [==============================] - 0s 168us/step - loss: 1.3511e-05 - acc: 1.0000 - val_loss: 0.7254 - val_acc: 0.9068\n",
            "Epoch 24/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.2916e-05 - acc: 1.0000 - val_loss: 0.7291 - val_acc: 0.9057\n",
            "Epoch 25/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.2247e-05 - acc: 1.0000 - val_loss: 0.7299 - val_acc: 0.9068\n",
            "Epoch 26/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.1657e-05 - acc: 1.0000 - val_loss: 0.7308 - val_acc: 0.9057\n",
            "Epoch 27/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.1154e-05 - acc: 1.0000 - val_loss: 0.7322 - val_acc: 0.9057\n",
            "Epoch 28/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0703e-05 - acc: 1.0000 - val_loss: 0.7361 - val_acc: 0.9068\n",
            "Epoch 29/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0074e-05 - acc: 1.0000 - val_loss: 0.7392 - val_acc: 0.9068\n",
            "Epoch 30/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 9.6674e-06 - acc: 1.0000 - val_loss: 0.7382 - val_acc: 0.9045\n",
            "Epoch 31/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 9.2009e-06 - acc: 1.0000 - val_loss: 0.7397 - val_acc: 0.9057\n",
            "Epoch 32/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 8.7730e-06 - acc: 1.0000 - val_loss: 0.7435 - val_acc: 0.9057\n",
            "Epoch 33/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 8.3470e-06 - acc: 1.0000 - val_loss: 0.7466 - val_acc: 0.9057\n",
            "Epoch 34/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 7.9563e-06 - acc: 1.0000 - val_loss: 0.7468 - val_acc: 0.9068\n",
            "Epoch 35/800\n",
            "789/789 [==============================] - 0s 198us/step - loss: 7.5992e-06 - acc: 1.0000 - val_loss: 0.7469 - val_acc: 0.9057\n",
            "Epoch 36/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 7.2290e-06 - acc: 1.0000 - val_loss: 0.7507 - val_acc: 0.9068\n",
            "Epoch 37/800\n",
            "789/789 [==============================] - 0s 202us/step - loss: 6.8831e-06 - acc: 1.0000 - val_loss: 0.7521 - val_acc: 0.9068\n",
            "Epoch 38/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 6.5763e-06 - acc: 1.0000 - val_loss: 0.7560 - val_acc: 0.9068\n",
            "Epoch 39/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 6.3192e-06 - acc: 1.0000 - val_loss: 0.7575 - val_acc: 0.9068\n",
            "Epoch 40/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 6.0043e-06 - acc: 1.0000 - val_loss: 0.7580 - val_acc: 0.9068\n",
            "Epoch 41/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 5.7363e-06 - acc: 1.0000 - val_loss: 0.7594 - val_acc: 0.9068\n",
            "Epoch 42/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 5.4683e-06 - acc: 1.0000 - val_loss: 0.7621 - val_acc: 0.9068\n",
            "Epoch 43/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 5.2117e-06 - acc: 1.0000 - val_loss: 0.7634 - val_acc: 0.9068\n",
            "Epoch 44/800\n",
            "789/789 [==============================] - 0s 203us/step - loss: 4.9715e-06 - acc: 1.0000 - val_loss: 0.7669 - val_acc: 0.9068\n",
            "Epoch 45/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 4.7507e-06 - acc: 1.0000 - val_loss: 0.7703 - val_acc: 0.9057\n",
            "Epoch 46/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 4.5404e-06 - acc: 1.0000 - val_loss: 0.7690 - val_acc: 0.9068\n",
            "Epoch 47/800\n",
            "789/789 [==============================] - 0s 198us/step - loss: 4.3482e-06 - acc: 1.0000 - val_loss: 0.7707 - val_acc: 0.9068\n",
            "Epoch 48/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 4.1352e-06 - acc: 1.0000 - val_loss: 0.7729 - val_acc: 0.9068\n",
            "Epoch 49/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 3.9512e-06 - acc: 1.0000 - val_loss: 0.7744 - val_acc: 0.9068\n",
            "Epoch 50/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 3.7797e-06 - acc: 1.0000 - val_loss: 0.7754 - val_acc: 0.9068\n",
            "Epoch 51/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 3.6070e-06 - acc: 1.0000 - val_loss: 0.7760 - val_acc: 0.9068\n",
            "Epoch 52/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 3.4594e-06 - acc: 1.0000 - val_loss: 0.7794 - val_acc: 0.9068\n",
            "Epoch 53/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 3.2964e-06 - acc: 1.0000 - val_loss: 0.7852 - val_acc: 0.9068\n",
            "Epoch 54/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 3.1535e-06 - acc: 1.0000 - val_loss: 0.7831 - val_acc: 0.9068\n",
            "Epoch 55/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 3.0124e-06 - acc: 1.0000 - val_loss: 0.7840 - val_acc: 0.9068\n",
            "Epoch 56/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 2.8824e-06 - acc: 1.0000 - val_loss: 0.7889 - val_acc: 0.9057\n",
            "Epoch 57/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 2.7674e-06 - acc: 1.0000 - val_loss: 0.7891 - val_acc: 0.9068\n",
            "Epoch 58/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 2.6314e-06 - acc: 1.0000 - val_loss: 0.7906 - val_acc: 0.9068\n",
            "Epoch 59/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 2.5085e-06 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.9068\n",
            "Epoch 60/800\n",
            "789/789 [==============================] - 0s 200us/step - loss: 2.3985e-06 - acc: 1.0000 - val_loss: 0.7956 - val_acc: 0.9057\n",
            "Epoch 61/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 2.2940e-06 - acc: 1.0000 - val_loss: 0.7953 - val_acc: 0.9068\n",
            "Epoch 62/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 2.2049e-06 - acc: 1.0000 - val_loss: 0.7964 - val_acc: 0.9068\n",
            "Epoch 63/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 2.1101e-06 - acc: 1.0000 - val_loss: 0.7983 - val_acc: 0.9068\n",
            "Epoch 64/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 2.0166e-06 - acc: 1.0000 - val_loss: 0.8026 - val_acc: 0.9068\n",
            "Epoch 65/800\n",
            "789/789 [==============================] - 0s 204us/step - loss: 1.9231e-06 - acc: 1.0000 - val_loss: 0.8020 - val_acc: 0.9068\n",
            "Epoch 66/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.8479e-06 - acc: 1.0000 - val_loss: 0.8046 - val_acc: 0.9068\n",
            "Epoch 67/800\n",
            "789/789 [==============================] - 0s 207us/step - loss: 1.7652e-06 - acc: 1.0000 - val_loss: 0.8089 - val_acc: 0.9068\n",
            "Epoch 68/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.6982e-06 - acc: 1.0000 - val_loss: 0.8091 - val_acc: 0.9068\n",
            "Epoch 69/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.6216e-06 - acc: 1.0000 - val_loss: 0.8084 - val_acc: 0.9068\n",
            "Epoch 70/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.5545e-06 - acc: 1.0000 - val_loss: 0.8112 - val_acc: 0.9068\n",
            "Epoch 71/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.4854e-06 - acc: 1.0000 - val_loss: 0.8143 - val_acc: 0.9068\n",
            "Epoch 72/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.4256e-06 - acc: 1.0000 - val_loss: 0.8147 - val_acc: 0.9068\n",
            "Epoch 73/800\n",
            "789/789 [==============================] - 0s 211us/step - loss: 1.3636e-06 - acc: 1.0000 - val_loss: 0.8177 - val_acc: 0.9068\n",
            "Epoch 74/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.3076e-06 - acc: 1.0000 - val_loss: 0.8205 - val_acc: 0.9068\n",
            "Epoch 75/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.2515e-06 - acc: 1.0000 - val_loss: 0.8194 - val_acc: 0.9068\n",
            "Epoch 76/800\n",
            "789/789 [==============================] - 0s 209us/step - loss: 1.1981e-06 - acc: 1.0000 - val_loss: 0.8228 - val_acc: 0.9068\n",
            "Epoch 77/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.1503e-06 - acc: 1.0000 - val_loss: 0.8217 - val_acc: 0.9068\n",
            "Epoch 78/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.1057e-06 - acc: 1.0000 - val_loss: 0.8238 - val_acc: 0.9068\n",
            "Epoch 79/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0595e-06 - acc: 1.0000 - val_loss: 0.8258 - val_acc: 0.9068\n",
            "Epoch 80/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0193e-06 - acc: 1.0000 - val_loss: 0.8294 - val_acc: 0.9057\n",
            "Epoch 81/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 9.7468e-07 - acc: 1.0000 - val_loss: 0.8304 - val_acc: 0.9068\n",
            "Epoch 82/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 9.3566e-07 - acc: 1.0000 - val_loss: 0.8303 - val_acc: 0.9068\n",
            "Epoch 83/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 8.9814e-07 - acc: 1.0000 - val_loss: 0.8343 - val_acc: 0.9068\n",
            "Epoch 84/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 8.6208e-07 - acc: 1.0000 - val_loss: 0.8356 - val_acc: 0.9068\n",
            "Epoch 85/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 8.2909e-07 - acc: 1.0000 - val_loss: 0.8371 - val_acc: 0.9068\n",
            "Epoch 86/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 7.9703e-07 - acc: 1.0000 - val_loss: 0.8398 - val_acc: 0.9068\n",
            "Epoch 87/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 7.6611e-07 - acc: 1.0000 - val_loss: 0.8398 - val_acc: 0.9068\n",
            "Epoch 88/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 7.3590e-07 - acc: 1.0000 - val_loss: 0.8407 - val_acc: 0.9068\n",
            "Epoch 89/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 7.0510e-07 - acc: 1.0000 - val_loss: 0.8453 - val_acc: 0.9057\n",
            "Epoch 90/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 6.8064e-07 - acc: 1.0000 - val_loss: 0.8450 - val_acc: 0.9068\n",
            "Epoch 91/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 6.5426e-07 - acc: 1.0000 - val_loss: 0.8445 - val_acc: 0.9068\n",
            "Epoch 92/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 6.2927e-07 - acc: 1.0000 - val_loss: 0.8484 - val_acc: 0.9068\n",
            "Epoch 93/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 6.0567e-07 - acc: 1.0000 - val_loss: 0.8496 - val_acc: 0.9068\n",
            "Epoch 94/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 5.8283e-07 - acc: 1.0000 - val_loss: 0.8495 - val_acc: 0.9068\n",
            "Epoch 95/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 5.6167e-07 - acc: 1.0000 - val_loss: 0.8514 - val_acc: 0.9068\n",
            "Epoch 96/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 5.4088e-07 - acc: 1.0000 - val_loss: 0.8521 - val_acc: 0.9057\n",
            "Epoch 97/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 5.2389e-07 - acc: 1.0000 - val_loss: 0.8549 - val_acc: 0.9068\n",
            "Epoch 98/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 5.0229e-07 - acc: 1.0000 - val_loss: 0.8578 - val_acc: 0.9068\n",
            "Epoch 99/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 4.8478e-07 - acc: 1.0000 - val_loss: 0.8592 - val_acc: 0.9068\n",
            "Epoch 100/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 4.6550e-07 - acc: 1.0000 - val_loss: 0.8602 - val_acc: 0.9068\n",
            "Epoch 101/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 4.5177e-07 - acc: 1.0000 - val_loss: 0.8623 - val_acc: 0.9068\n",
            "Epoch 102/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 4.3524e-07 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.9068\n",
            "Epoch 103/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 4.2007e-07 - acc: 1.0000 - val_loss: 0.8640 - val_acc: 0.9068\n",
            "Epoch 104/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 4.0525e-07 - acc: 1.0000 - val_loss: 0.8688 - val_acc: 0.9068\n",
            "Epoch 105/800\n",
            "789/789 [==============================] - 0s 205us/step - loss: 3.9224e-07 - acc: 1.0000 - val_loss: 0.8688 - val_acc: 0.9068\n",
            "Epoch 106/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 3.7800e-07 - acc: 1.0000 - val_loss: 0.8706 - val_acc: 0.9068\n",
            "Epoch 107/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 3.6701e-07 - acc: 1.0000 - val_loss: 0.8722 - val_acc: 0.9068\n",
            "Epoch 108/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 3.5407e-07 - acc: 1.0000 - val_loss: 0.8716 - val_acc: 0.9057\n",
            "Epoch 109/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 3.4254e-07 - acc: 1.0000 - val_loss: 0.8759 - val_acc: 0.9057\n",
            "Epoch 110/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 3.3204e-07 - acc: 1.0000 - val_loss: 0.8758 - val_acc: 0.9068\n",
            "Epoch 111/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 3.2136e-07 - acc: 1.0000 - val_loss: 0.8781 - val_acc: 0.9057\n",
            "Epoch 112/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 3.1183e-07 - acc: 1.0000 - val_loss: 0.8779 - val_acc: 0.9068\n",
            "Epoch 113/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 3.0232e-07 - acc: 1.0000 - val_loss: 0.8789 - val_acc: 0.9057\n",
            "Epoch 114/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 2.9283e-07 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.9045\n",
            "Epoch 115/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 2.8415e-07 - acc: 1.0000 - val_loss: 0.8823 - val_acc: 0.9057\n",
            "Epoch 116/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 2.7535e-07 - acc: 1.0000 - val_loss: 0.8853 - val_acc: 0.9068\n",
            "Epoch 117/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 2.6760e-07 - acc: 1.0000 - val_loss: 0.8899 - val_acc: 0.9057\n",
            "Epoch 118/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 2.6056e-07 - acc: 1.0000 - val_loss: 0.8868 - val_acc: 0.9045\n",
            "Epoch 119/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 2.5292e-07 - acc: 1.0000 - val_loss: 0.8876 - val_acc: 0.9068\n",
            "Epoch 120/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 2.4550e-07 - acc: 1.0000 - val_loss: 0.8933 - val_acc: 0.9045\n",
            "Epoch 121/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 2.3921e-07 - acc: 1.0000 - val_loss: 0.8926 - val_acc: 0.9068\n",
            "Epoch 122/800\n",
            "789/789 [==============================] - 0s 170us/step - loss: 2.3340e-07 - acc: 1.0000 - val_loss: 0.8935 - val_acc: 0.9057\n",
            "Epoch 123/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 2.2660e-07 - acc: 1.0000 - val_loss: 0.8931 - val_acc: 0.9057\n",
            "Epoch 124/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 2.2092e-07 - acc: 1.0000 - val_loss: 0.8956 - val_acc: 0.9057\n",
            "Epoch 125/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 2.1549e-07 - acc: 1.0000 - val_loss: 0.8969 - val_acc: 0.9057\n",
            "Epoch 126/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 2.1033e-07 - acc: 1.0000 - val_loss: 0.8961 - val_acc: 0.9057\n",
            "Epoch 127/800\n",
            "789/789 [==============================] - 0s 169us/step - loss: 2.0513e-07 - acc: 1.0000 - val_loss: 0.8996 - val_acc: 0.9057\n",
            "Epoch 128/800\n",
            "789/789 [==============================] - 0s 167us/step - loss: 2.0012e-07 - acc: 1.0000 - val_loss: 0.8997 - val_acc: 0.9057\n",
            "Epoch 129/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.9545e-07 - acc: 1.0000 - val_loss: 0.9011 - val_acc: 0.9057\n",
            "Epoch 130/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.9105e-07 - acc: 1.0000 - val_loss: 0.9008 - val_acc: 0.9057\n",
            "Epoch 131/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.8686e-07 - acc: 1.0000 - val_loss: 0.9037 - val_acc: 0.9045\n",
            "Epoch 132/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.8310e-07 - acc: 1.0000 - val_loss: 0.9058 - val_acc: 0.9045\n",
            "Epoch 133/800\n",
            "789/789 [==============================] - 0s 169us/step - loss: 1.7894e-07 - acc: 1.0000 - val_loss: 0.9044 - val_acc: 0.9068\n",
            "Epoch 134/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.7514e-07 - acc: 1.0000 - val_loss: 0.9062 - val_acc: 0.9057\n",
            "Epoch 135/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.7216e-07 - acc: 1.0000 - val_loss: 0.9077 - val_acc: 0.9045\n",
            "Epoch 136/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.6812e-07 - acc: 1.0000 - val_loss: 0.9084 - val_acc: 0.9045\n",
            "Epoch 137/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.6503e-07 - acc: 1.0000 - val_loss: 0.9097 - val_acc: 0.9057\n",
            "Epoch 138/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.6257e-07 - acc: 1.0000 - val_loss: 0.9112 - val_acc: 0.9057\n",
            "Epoch 139/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.5921e-07 - acc: 1.0000 - val_loss: 0.9121 - val_acc: 0.9045\n",
            "Epoch 140/800\n",
            "789/789 [==============================] - 0s 170us/step - loss: 1.5644e-07 - acc: 1.0000 - val_loss: 0.9116 - val_acc: 0.9057\n",
            "Epoch 141/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.5389e-07 - acc: 1.0000 - val_loss: 0.9146 - val_acc: 0.9057\n",
            "Epoch 142/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.5108e-07 - acc: 1.0000 - val_loss: 0.9166 - val_acc: 0.9045\n",
            "Epoch 143/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.4867e-07 - acc: 1.0000 - val_loss: 0.9156 - val_acc: 0.9057\n",
            "Epoch 144/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.4630e-07 - acc: 1.0000 - val_loss: 0.9187 - val_acc: 0.9057\n",
            "Epoch 145/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.4391e-07 - acc: 1.0000 - val_loss: 0.9180 - val_acc: 0.9068\n",
            "Epoch 146/800\n",
            "789/789 [==============================] - 0s 207us/step - loss: 1.4215e-07 - acc: 1.0000 - val_loss: 0.9196 - val_acc: 0.9045\n",
            "Epoch 147/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.4015e-07 - acc: 1.0000 - val_loss: 0.9191 - val_acc: 0.9045\n",
            "Epoch 148/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.3824e-07 - acc: 1.0000 - val_loss: 0.9223 - val_acc: 0.9057\n",
            "Epoch 149/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.3614e-07 - acc: 1.0000 - val_loss: 0.9224 - val_acc: 0.9045\n",
            "Epoch 150/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.3463e-07 - acc: 1.0000 - val_loss: 0.9249 - val_acc: 0.9034\n",
            "Epoch 151/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.3286e-07 - acc: 1.0000 - val_loss: 0.9240 - val_acc: 0.9057\n",
            "Epoch 152/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.3122e-07 - acc: 1.0000 - val_loss: 0.9245 - val_acc: 0.9045\n",
            "Epoch 153/800\n",
            "789/789 [==============================] - 0s 167us/step - loss: 1.2959e-07 - acc: 1.0000 - val_loss: 0.9241 - val_acc: 0.9045\n",
            "Epoch 154/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.2833e-07 - acc: 1.0000 - val_loss: 0.9272 - val_acc: 0.9045\n",
            "Epoch 155/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.2684e-07 - acc: 1.0000 - val_loss: 0.9276 - val_acc: 0.9034\n",
            "Epoch 156/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.2524e-07 - acc: 1.0000 - val_loss: 0.9285 - val_acc: 0.9034\n",
            "Epoch 157/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.2421e-07 - acc: 1.0000 - val_loss: 0.9281 - val_acc: 0.9045\n",
            "Epoch 158/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.2309e-07 - acc: 1.0000 - val_loss: 0.9296 - val_acc: 0.9034\n",
            "Epoch 159/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.2175e-07 - acc: 1.0000 - val_loss: 0.9292 - val_acc: 0.9045\n",
            "Epoch 160/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.2055e-07 - acc: 1.0000 - val_loss: 0.9319 - val_acc: 0.9034\n",
            "Epoch 161/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.1964e-07 - acc: 1.0000 - val_loss: 0.9313 - val_acc: 0.9045\n",
            "Epoch 162/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.1873e-07 - acc: 1.0000 - val_loss: 0.9333 - val_acc: 0.9034\n",
            "Epoch 163/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.1748e-07 - acc: 1.0000 - val_loss: 0.9333 - val_acc: 0.9034\n",
            "Epoch 164/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.1665e-07 - acc: 1.0000 - val_loss: 0.9342 - val_acc: 0.9045\n",
            "Epoch 165/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.1607e-07 - acc: 1.0000 - val_loss: 0.9343 - val_acc: 0.9057\n",
            "Epoch 166/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.1517e-07 - acc: 1.0000 - val_loss: 0.9371 - val_acc: 0.9045\n",
            "Epoch 167/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.1437e-07 - acc: 1.0000 - val_loss: 0.9372 - val_acc: 0.9045\n",
            "Epoch 168/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.1359e-07 - acc: 1.0000 - val_loss: 0.9371 - val_acc: 0.9045\n",
            "Epoch 169/800\n",
            "789/789 [==============================] - 0s 166us/step - loss: 1.1264e-07 - acc: 1.0000 - val_loss: 0.9379 - val_acc: 0.9057\n",
            "Epoch 170/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.1197e-07 - acc: 1.0000 - val_loss: 0.9394 - val_acc: 0.9057\n",
            "Epoch 171/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.1170e-07 - acc: 1.0000 - val_loss: 0.9404 - val_acc: 0.9045\n",
            "Epoch 172/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.1113e-07 - acc: 1.0000 - val_loss: 0.9409 - val_acc: 0.9057\n",
            "Epoch 173/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.1030e-07 - acc: 1.0000 - val_loss: 0.9425 - val_acc: 0.9034\n",
            "Epoch 174/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.1008e-07 - acc: 1.0000 - val_loss: 0.9416 - val_acc: 0.9057\n",
            "Epoch 175/800\n",
            "789/789 [==============================] - 0s 170us/step - loss: 1.0919e-07 - acc: 1.0000 - val_loss: 0.9422 - val_acc: 0.9045\n",
            "Epoch 176/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0879e-07 - acc: 1.0000 - val_loss: 0.9423 - val_acc: 0.9045\n",
            "Epoch 177/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0837e-07 - acc: 1.0000 - val_loss: 0.9439 - val_acc: 0.9045\n",
            "Epoch 178/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0812e-07 - acc: 1.0000 - val_loss: 0.9449 - val_acc: 0.9045\n",
            "Epoch 179/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0763e-07 - acc: 1.0000 - val_loss: 0.9455 - val_acc: 0.9045\n",
            "Epoch 180/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0723e-07 - acc: 1.0000 - val_loss: 0.9455 - val_acc: 0.9045\n",
            "Epoch 181/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0704e-07 - acc: 1.0000 - val_loss: 0.9464 - val_acc: 0.9045\n",
            "Epoch 182/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0639e-07 - acc: 1.0000 - val_loss: 0.9465 - val_acc: 0.9045\n",
            "Epoch 183/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0636e-07 - acc: 1.0000 - val_loss: 0.9477 - val_acc: 0.9045\n",
            "Epoch 184/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0585e-07 - acc: 1.0000 - val_loss: 0.9481 - val_acc: 0.9045\n",
            "Epoch 185/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0571e-07 - acc: 1.0000 - val_loss: 0.9485 - val_acc: 0.9045\n",
            "Epoch 186/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0542e-07 - acc: 1.0000 - val_loss: 0.9482 - val_acc: 0.9045\n",
            "Epoch 187/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0525e-07 - acc: 1.0000 - val_loss: 0.9499 - val_acc: 0.9045\n",
            "Epoch 188/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0512e-07 - acc: 1.0000 - val_loss: 0.9501 - val_acc: 0.9045\n",
            "Epoch 189/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0499e-07 - acc: 1.0000 - val_loss: 0.9514 - val_acc: 0.9045\n",
            "Epoch 190/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0468e-07 - acc: 1.0000 - val_loss: 0.9505 - val_acc: 0.9045\n",
            "Epoch 191/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0452e-07 - acc: 1.0000 - val_loss: 0.9523 - val_acc: 0.9034\n",
            "Epoch 192/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0434e-07 - acc: 1.0000 - val_loss: 0.9528 - val_acc: 0.9045\n",
            "Epoch 193/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0415e-07 - acc: 1.0000 - val_loss: 0.9527 - val_acc: 0.9045\n",
            "Epoch 194/800\n",
            "789/789 [==============================] - 0s 207us/step - loss: 1.0413e-07 - acc: 1.0000 - val_loss: 0.9538 - val_acc: 0.9045\n",
            "Epoch 195/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0387e-07 - acc: 1.0000 - val_loss: 0.9539 - val_acc: 0.9045\n",
            "Epoch 196/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0384e-07 - acc: 1.0000 - val_loss: 0.9551 - val_acc: 0.9034\n",
            "Epoch 197/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0372e-07 - acc: 1.0000 - val_loss: 0.9556 - val_acc: 0.9034\n",
            "Epoch 198/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0345e-07 - acc: 1.0000 - val_loss: 0.9561 - val_acc: 0.9045\n",
            "Epoch 199/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0341e-07 - acc: 1.0000 - val_loss: 0.9562 - val_acc: 0.9045\n",
            "Epoch 200/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0339e-07 - acc: 1.0000 - val_loss: 0.9570 - val_acc: 0.9045\n",
            "Epoch 201/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0334e-07 - acc: 1.0000 - val_loss: 0.9579 - val_acc: 0.9045\n",
            "Epoch 202/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0314e-07 - acc: 1.0000 - val_loss: 0.9576 - val_acc: 0.9045\n",
            "Epoch 203/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0299e-07 - acc: 1.0000 - val_loss: 0.9586 - val_acc: 0.9034\n",
            "Epoch 204/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0306e-07 - acc: 1.0000 - val_loss: 0.9592 - val_acc: 0.9045\n",
            "Epoch 205/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0290e-07 - acc: 1.0000 - val_loss: 0.9583 - val_acc: 0.9045\n",
            "Epoch 206/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0293e-07 - acc: 1.0000 - val_loss: 0.9626 - val_acc: 0.9045\n",
            "Epoch 207/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0291e-07 - acc: 1.0000 - val_loss: 0.9600 - val_acc: 0.9034\n",
            "Epoch 208/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0282e-07 - acc: 1.0000 - val_loss: 0.9620 - val_acc: 0.9045\n",
            "Epoch 209/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0274e-07 - acc: 1.0000 - val_loss: 0.9615 - val_acc: 0.9034\n",
            "Epoch 210/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0268e-07 - acc: 1.0000 - val_loss: 0.9607 - val_acc: 0.9034\n",
            "Epoch 211/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0253e-07 - acc: 1.0000 - val_loss: 0.9621 - val_acc: 0.9034\n",
            "Epoch 212/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0264e-07 - acc: 1.0000 - val_loss: 0.9613 - val_acc: 0.9034\n",
            "Epoch 213/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0252e-07 - acc: 1.0000 - val_loss: 0.9621 - val_acc: 0.9034\n",
            "Epoch 214/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0255e-07 - acc: 1.0000 - val_loss: 0.9625 - val_acc: 0.9034\n",
            "Epoch 215/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0264e-07 - acc: 1.0000 - val_loss: 0.9649 - val_acc: 0.9034\n",
            "Epoch 216/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0258e-07 - acc: 1.0000 - val_loss: 0.9640 - val_acc: 0.9045\n",
            "Epoch 217/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0247e-07 - acc: 1.0000 - val_loss: 0.9644 - val_acc: 0.9034\n",
            "Epoch 218/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0245e-07 - acc: 1.0000 - val_loss: 0.9642 - val_acc: 0.9034\n",
            "Epoch 219/800\n",
            "789/789 [==============================] - 0s 201us/step - loss: 1.0242e-07 - acc: 1.0000 - val_loss: 0.9662 - val_acc: 0.9034\n",
            "Epoch 220/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0251e-07 - acc: 1.0000 - val_loss: 0.9677 - val_acc: 0.9034\n",
            "Epoch 221/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0237e-07 - acc: 1.0000 - val_loss: 0.9674 - val_acc: 0.9034\n",
            "Epoch 222/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0240e-07 - acc: 1.0000 - val_loss: 0.9680 - val_acc: 0.9034\n",
            "Epoch 223/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0244e-07 - acc: 1.0000 - val_loss: 0.9663 - val_acc: 0.9034\n",
            "Epoch 224/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0229e-07 - acc: 1.0000 - val_loss: 0.9683 - val_acc: 0.9034\n",
            "Epoch 225/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0228e-07 - acc: 1.0000 - val_loss: 0.9672 - val_acc: 0.9034\n",
            "Epoch 226/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0237e-07 - acc: 1.0000 - val_loss: 0.9686 - val_acc: 0.9034\n",
            "Epoch 227/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0230e-07 - acc: 1.0000 - val_loss: 0.9693 - val_acc: 0.9034\n",
            "Epoch 228/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0223e-07 - acc: 1.0000 - val_loss: 0.9695 - val_acc: 0.9034\n",
            "Epoch 229/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0233e-07 - acc: 1.0000 - val_loss: 0.9704 - val_acc: 0.9034\n",
            "Epoch 230/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0231e-07 - acc: 1.0000 - val_loss: 0.9687 - val_acc: 0.9034\n",
            "Epoch 231/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0229e-07 - acc: 1.0000 - val_loss: 0.9705 - val_acc: 0.9034\n",
            "Epoch 232/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0229e-07 - acc: 1.0000 - val_loss: 0.9697 - val_acc: 0.9034\n",
            "Epoch 233/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.0220e-07 - acc: 1.0000 - val_loss: 0.9712 - val_acc: 0.9034\n",
            "Epoch 234/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0228e-07 - acc: 1.0000 - val_loss: 0.9705 - val_acc: 0.9034\n",
            "Epoch 235/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0221e-07 - acc: 1.0000 - val_loss: 0.9716 - val_acc: 0.9034\n",
            "Epoch 236/800\n",
            "789/789 [==============================] - 0s 198us/step - loss: 1.0220e-07 - acc: 1.0000 - val_loss: 0.9711 - val_acc: 0.9034\n",
            "Epoch 237/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0222e-07 - acc: 1.0000 - val_loss: 0.9725 - val_acc: 0.9034\n",
            "Epoch 238/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0222e-07 - acc: 1.0000 - val_loss: 0.9711 - val_acc: 0.9034\n",
            "Epoch 239/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0214e-07 - acc: 1.0000 - val_loss: 0.9712 - val_acc: 0.9034\n",
            "Epoch 240/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0217e-07 - acc: 1.0000 - val_loss: 0.9726 - val_acc: 0.9034\n",
            "Epoch 241/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0214e-07 - acc: 1.0000 - val_loss: 0.9734 - val_acc: 0.9034\n",
            "Epoch 242/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0217e-07 - acc: 1.0000 - val_loss: 0.9722 - val_acc: 0.9034\n",
            "Epoch 243/800\n",
            "789/789 [==============================] - 0s 198us/step - loss: 1.0210e-07 - acc: 1.0000 - val_loss: 0.9718 - val_acc: 0.9034\n",
            "Epoch 244/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0215e-07 - acc: 1.0000 - val_loss: 0.9733 - val_acc: 0.9034\n",
            "Epoch 245/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0215e-07 - acc: 1.0000 - val_loss: 0.9736 - val_acc: 0.9034\n",
            "Epoch 246/800\n",
            "789/789 [==============================] - 0s 208us/step - loss: 1.0217e-07 - acc: 1.0000 - val_loss: 0.9756 - val_acc: 0.9034\n",
            "Epoch 247/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0211e-07 - acc: 1.0000 - val_loss: 0.9755 - val_acc: 0.9034\n",
            "Epoch 248/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0212e-07 - acc: 1.0000 - val_loss: 0.9734 - val_acc: 0.9034\n",
            "Epoch 249/800\n",
            "789/789 [==============================] - 0s 169us/step - loss: 1.0212e-07 - acc: 1.0000 - val_loss: 0.9745 - val_acc: 0.9034\n",
            "Epoch 250/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0211e-07 - acc: 1.0000 - val_loss: 0.9755 - val_acc: 0.9034\n",
            "Epoch 251/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0210e-07 - acc: 1.0000 - val_loss: 0.9751 - val_acc: 0.9034\n",
            "Epoch 252/800\n",
            "789/789 [==============================] - 0s 205us/step - loss: 1.0206e-07 - acc: 1.0000 - val_loss: 0.9751 - val_acc: 0.9034\n",
            "Epoch 253/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.0208e-07 - acc: 1.0000 - val_loss: 0.9755 - val_acc: 0.9034\n",
            "Epoch 254/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0212e-07 - acc: 1.0000 - val_loss: 0.9755 - val_acc: 0.9034\n",
            "Epoch 255/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0210e-07 - acc: 1.0000 - val_loss: 0.9754 - val_acc: 0.9034\n",
            "Epoch 256/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0209e-07 - acc: 1.0000 - val_loss: 0.9771 - val_acc: 0.9034\n",
            "Epoch 257/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0206e-07 - acc: 1.0000 - val_loss: 0.9765 - val_acc: 0.9034\n",
            "Epoch 258/800\n",
            "789/789 [==============================] - 0s 170us/step - loss: 1.0203e-07 - acc: 1.0000 - val_loss: 0.9760 - val_acc: 0.9034\n",
            "Epoch 259/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0206e-07 - acc: 1.0000 - val_loss: 0.9763 - val_acc: 0.9034\n",
            "Epoch 260/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0204e-07 - acc: 1.0000 - val_loss: 0.9760 - val_acc: 0.9034\n",
            "Epoch 261/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0208e-07 - acc: 1.0000 - val_loss: 0.9755 - val_acc: 0.9034\n",
            "Epoch 262/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0203e-07 - acc: 1.0000 - val_loss: 0.9766 - val_acc: 0.9034\n",
            "Epoch 263/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0205e-07 - acc: 1.0000 - val_loss: 0.9772 - val_acc: 0.9034\n",
            "Epoch 264/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0206e-07 - acc: 1.0000 - val_loss: 0.9765 - val_acc: 0.9034\n",
            "Epoch 265/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0205e-07 - acc: 1.0000 - val_loss: 0.9780 - val_acc: 0.9034\n",
            "Epoch 266/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0207e-07 - acc: 1.0000 - val_loss: 0.9777 - val_acc: 0.9034\n",
            "Epoch 267/800\n",
            "789/789 [==============================] - 0s 169us/step - loss: 1.0205e-07 - acc: 1.0000 - val_loss: 0.9784 - val_acc: 0.9034\n",
            "Epoch 268/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0212e-07 - acc: 1.0000 - val_loss: 0.9780 - val_acc: 0.9034\n",
            "Epoch 269/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0208e-07 - acc: 1.0000 - val_loss: 0.9792 - val_acc: 0.9034\n",
            "Epoch 270/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0202e-07 - acc: 1.0000 - val_loss: 0.9790 - val_acc: 0.9034\n",
            "Epoch 271/800\n",
            "789/789 [==============================] - 0s 166us/step - loss: 1.0204e-07 - acc: 1.0000 - val_loss: 0.9793 - val_acc: 0.9034\n",
            "Epoch 272/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0203e-07 - acc: 1.0000 - val_loss: 0.9787 - val_acc: 0.9034\n",
            "Epoch 273/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0205e-07 - acc: 1.0000 - val_loss: 0.9788 - val_acc: 0.9034\n",
            "Epoch 274/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 1.0201e-07 - acc: 1.0000 - val_loss: 0.9793 - val_acc: 0.9045\n",
            "Epoch 275/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0206e-07 - acc: 1.0000 - val_loss: 0.9783 - val_acc: 0.9045\n",
            "Epoch 276/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0201e-07 - acc: 1.0000 - val_loss: 0.9781 - val_acc: 0.9034\n",
            "Epoch 277/800\n",
            "789/789 [==============================] - 0s 200us/step - loss: 1.0201e-07 - acc: 1.0000 - val_loss: 0.9785 - val_acc: 0.9034\n",
            "Epoch 278/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0203e-07 - acc: 1.0000 - val_loss: 0.9790 - val_acc: 0.9045\n",
            "Epoch 279/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9782 - val_acc: 0.9034\n",
            "Epoch 280/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0202e-07 - acc: 1.0000 - val_loss: 0.9787 - val_acc: 0.9045\n",
            "Epoch 281/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0202e-07 - acc: 1.0000 - val_loss: 0.9788 - val_acc: 0.9034\n",
            "Epoch 282/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0203e-07 - acc: 1.0000 - val_loss: 0.9797 - val_acc: 0.9045\n",
            "Epoch 283/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0202e-07 - acc: 1.0000 - val_loss: 0.9804 - val_acc: 0.9045\n",
            "Epoch 284/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0202e-07 - acc: 1.0000 - val_loss: 0.9811 - val_acc: 0.9045\n",
            "Epoch 285/800\n",
            "789/789 [==============================] - 0s 199us/step - loss: 1.0201e-07 - acc: 1.0000 - val_loss: 0.9813 - val_acc: 0.9045\n",
            "Epoch 286/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0201e-07 - acc: 1.0000 - val_loss: 0.9811 - val_acc: 0.9034\n",
            "Epoch 287/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0202e-07 - acc: 1.0000 - val_loss: 0.9811 - val_acc: 0.9045\n",
            "Epoch 288/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0200e-07 - acc: 1.0000 - val_loss: 0.9814 - val_acc: 0.9045\n",
            "Epoch 289/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9827 - val_acc: 0.9034\n",
            "Epoch 290/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0201e-07 - acc: 1.0000 - val_loss: 0.9816 - val_acc: 0.9045\n",
            "Epoch 291/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.9806 - val_acc: 0.9045\n",
            "Epoch 292/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.9825 - val_acc: 0.9034\n",
            "Epoch 293/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9811 - val_acc: 0.9045\n",
            "Epoch 294/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9812 - val_acc: 0.9034\n",
            "Epoch 295/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9814 - val_acc: 0.9045\n",
            "Epoch 296/800\n",
            "789/789 [==============================] - 0s 206us/step - loss: 1.0200e-07 - acc: 1.0000 - val_loss: 0.9821 - val_acc: 0.9034\n",
            "Epoch 297/800\n",
            "789/789 [==============================] - 0s 206us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9824 - val_acc: 0.9034\n",
            "Epoch 298/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.0202e-07 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.9034\n",
            "Epoch 299/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0200e-07 - acc: 1.0000 - val_loss: 0.9823 - val_acc: 0.9034\n",
            "Epoch 300/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9820 - val_acc: 0.9034\n",
            "Epoch 301/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0201e-07 - acc: 1.0000 - val_loss: 0.9805 - val_acc: 0.9034\n",
            "Epoch 302/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.9814 - val_acc: 0.9034\n",
            "Epoch 303/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9833 - val_acc: 0.9034\n",
            "Epoch 304/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0200e-07 - acc: 1.0000 - val_loss: 0.9816 - val_acc: 0.9034\n",
            "Epoch 305/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0200e-07 - acc: 1.0000 - val_loss: 0.9795 - val_acc: 0.9034\n",
            "Epoch 306/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9815 - val_acc: 0.9034\n",
            "Epoch 307/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0201e-07 - acc: 1.0000 - val_loss: 0.9817 - val_acc: 0.9034\n",
            "Epoch 308/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9824 - val_acc: 0.9034\n",
            "Epoch 309/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.9814 - val_acc: 0.9034\n",
            "Epoch 310/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9796 - val_acc: 0.9034\n",
            "Epoch 311/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0201e-07 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.9045\n",
            "Epoch 312/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9815 - val_acc: 0.9034\n",
            "Epoch 313/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.9821 - val_acc: 0.9045\n",
            "Epoch 314/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9812 - val_acc: 0.9045\n",
            "Epoch 315/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.9826 - val_acc: 0.9045\n",
            "Epoch 316/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9830 - val_acc: 0.9034\n",
            "Epoch 317/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9826 - val_acc: 0.9034\n",
            "Epoch 318/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9827 - val_acc: 0.9034\n",
            "Epoch 319/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9826 - val_acc: 0.9034\n",
            "Epoch 320/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9817 - val_acc: 0.9034\n",
            "Epoch 321/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9820 - val_acc: 0.9045\n",
            "Epoch 322/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.9045\n",
            "Epoch 323/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9825 - val_acc: 0.9034\n",
            "Epoch 324/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.9034\n",
            "Epoch 325/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9844 - val_acc: 0.9034\n",
            "Epoch 326/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.9842 - val_acc: 0.9034\n",
            "Epoch 327/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9846 - val_acc: 0.9034\n",
            "Epoch 328/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9829 - val_acc: 0.9034\n",
            "Epoch 329/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.9034\n",
            "Epoch 330/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9837 - val_acc: 0.9034\n",
            "Epoch 331/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9834 - val_acc: 0.9034\n",
            "Epoch 332/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.9848 - val_acc: 0.9045\n",
            "Epoch 333/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9856 - val_acc: 0.9034\n",
            "Epoch 334/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9839 - val_acc: 0.9034\n",
            "Epoch 335/800\n",
            "789/789 [==============================] - 0s 201us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9838 - val_acc: 0.9034\n",
            "Epoch 336/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0199e-07 - acc: 1.0000 - val_loss: 0.9845 - val_acc: 0.9034\n",
            "Epoch 337/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9824 - val_acc: 0.9034\n",
            "Epoch 338/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9830 - val_acc: 0.9034\n",
            "Epoch 339/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9824 - val_acc: 0.9045\n",
            "Epoch 340/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9837 - val_acc: 0.9045\n",
            "Epoch 341/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.9034\n",
            "Epoch 342/800\n",
            "789/789 [==============================] - 0s 205us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9850 - val_acc: 0.9034\n",
            "Epoch 343/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9853 - val_acc: 0.9034\n",
            "Epoch 344/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0198e-07 - acc: 1.0000 - val_loss: 0.9860 - val_acc: 0.9034\n",
            "Epoch 345/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9845 - val_acc: 0.9034\n",
            "Epoch 346/800\n",
            "789/789 [==============================] - 0s 204us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9845 - val_acc: 0.9034\n",
            "Epoch 347/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.9034\n",
            "Epoch 348/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9846 - val_acc: 0.9034\n",
            "Epoch 349/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9845 - val_acc: 0.9034\n",
            "Epoch 350/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9848 - val_acc: 0.9034\n",
            "Epoch 351/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9845 - val_acc: 0.9034\n",
            "Epoch 352/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9850 - val_acc: 0.9034\n",
            "Epoch 353/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9861 - val_acc: 0.9034\n",
            "Epoch 354/800\n",
            "789/789 [==============================] - 0s 200us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9854 - val_acc: 0.9034\n",
            "Epoch 355/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9846 - val_acc: 0.9034\n",
            "Epoch 356/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9861 - val_acc: 0.9034\n",
            "Epoch 357/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9864 - val_acc: 0.9034\n",
            "Epoch 358/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9863 - val_acc: 0.9034\n",
            "Epoch 359/800\n",
            "789/789 [==============================] - 0s 227us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9863 - val_acc: 0.9034\n",
            "Epoch 360/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9859 - val_acc: 0.9034\n",
            "Epoch 361/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9862 - val_acc: 0.9034\n",
            "Epoch 362/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9852 - val_acc: 0.9034\n",
            "Epoch 363/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9876 - val_acc: 0.9034\n",
            "Epoch 364/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9869 - val_acc: 0.9034\n",
            "Epoch 365/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9866 - val_acc: 0.9034\n",
            "Epoch 366/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9878 - val_acc: 0.9034\n",
            "Epoch 367/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0197e-07 - acc: 1.0000 - val_loss: 0.9870 - val_acc: 0.9034\n",
            "Epoch 368/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9863 - val_acc: 0.9034\n",
            "Epoch 369/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9876 - val_acc: 0.9034\n",
            "Epoch 370/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9875 - val_acc: 0.9034\n",
            "Epoch 371/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9877 - val_acc: 0.9034\n",
            "Epoch 372/800\n",
            "789/789 [==============================] - 0s 203us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9870 - val_acc: 0.9034\n",
            "Epoch 373/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9877 - val_acc: 0.9034\n",
            "Epoch 374/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9870 - val_acc: 0.9034\n",
            "Epoch 375/800\n",
            "789/789 [==============================] - 0s 211us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9867 - val_acc: 0.9034\n",
            "Epoch 376/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9874 - val_acc: 0.9034\n",
            "Epoch 377/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9879 - val_acc: 0.9034\n",
            "Epoch 378/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9880 - val_acc: 0.9034\n",
            "Epoch 379/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.9045\n",
            "Epoch 380/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9865 - val_acc: 0.9045\n",
            "Epoch 381/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9873 - val_acc: 0.9034\n",
            "Epoch 382/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9875 - val_acc: 0.9034\n",
            "Epoch 383/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9885 - val_acc: 0.9034\n",
            "Epoch 384/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9884 - val_acc: 0.9034\n",
            "Epoch 385/800\n",
            "789/789 [==============================] - 0s 202us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9877 - val_acc: 0.9034\n",
            "Epoch 386/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9865 - val_acc: 0.9034\n",
            "Epoch 387/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9889 - val_acc: 0.9034\n",
            "Epoch 388/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9880 - val_acc: 0.9034\n",
            "Epoch 389/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9876 - val_acc: 0.9034\n",
            "Epoch 390/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9880 - val_acc: 0.9034\n",
            "Epoch 391/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9877 - val_acc: 0.9045\n",
            "Epoch 392/800\n",
            "789/789 [==============================] - 0s 203us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9868 - val_acc: 0.9045\n",
            "Epoch 393/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9884 - val_acc: 0.9045\n",
            "Epoch 394/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9878 - val_acc: 0.9034\n",
            "Epoch 395/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9871 - val_acc: 0.9034\n",
            "Epoch 396/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9874 - val_acc: 0.9034\n",
            "Epoch 397/800\n",
            "789/789 [==============================] - 0s 169us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9867 - val_acc: 0.9034\n",
            "Epoch 398/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9883 - val_acc: 0.9034\n",
            "Epoch 399/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9880 - val_acc: 0.9034\n",
            "Epoch 400/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9873 - val_acc: 0.9034\n",
            "Epoch 401/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9883 - val_acc: 0.9034\n",
            "Epoch 402/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9882 - val_acc: 0.9034\n",
            "Epoch 403/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9893 - val_acc: 0.9034\n",
            "Epoch 404/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9899 - val_acc: 0.9034\n",
            "Epoch 405/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9887 - val_acc: 0.9034\n",
            "Epoch 406/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.9034\n",
            "Epoch 407/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9898 - val_acc: 0.9034\n",
            "Epoch 408/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9889 - val_acc: 0.9034\n",
            "Epoch 409/800\n",
            "789/789 [==============================] - 0s 205us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9902 - val_acc: 0.9034\n",
            "Epoch 410/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.9034\n",
            "Epoch 411/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9900 - val_acc: 0.9034\n",
            "Epoch 412/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9886 - val_acc: 0.9034\n",
            "Epoch 413/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9886 - val_acc: 0.9034\n",
            "Epoch 414/800\n",
            "789/789 [==============================] - 0s 206us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9882 - val_acc: 0.9034\n",
            "Epoch 415/800\n",
            "789/789 [==============================] - 0s 199us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.9045\n",
            "Epoch 416/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9882 - val_acc: 0.9034\n",
            "Epoch 417/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9880 - val_acc: 0.9045\n",
            "Epoch 418/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9884 - val_acc: 0.9045\n",
            "Epoch 419/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9895 - val_acc: 0.9034\n",
            "Epoch 420/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9903 - val_acc: 0.9045\n",
            "Epoch 421/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.9045\n",
            "Epoch 422/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.9045\n",
            "Epoch 423/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9894 - val_acc: 0.9045\n",
            "Epoch 424/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9892 - val_acc: 0.9045\n",
            "Epoch 425/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.9045\n",
            "Epoch 426/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.9045\n",
            "Epoch 427/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9895 - val_acc: 0.9045\n",
            "Epoch 428/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9902 - val_acc: 0.9045\n",
            "Epoch 429/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9905 - val_acc: 0.9045\n",
            "Epoch 430/800\n",
            "789/789 [==============================] - 0s 169us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9910 - val_acc: 0.9045\n",
            "Epoch 431/800\n",
            "789/789 [==============================] - 0s 220us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9910 - val_acc: 0.9045\n",
            "Epoch 432/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9908 - val_acc: 0.9045\n",
            "Epoch 433/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9907 - val_acc: 0.9034\n",
            "Epoch 434/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9899 - val_acc: 0.9045\n",
            "Epoch 435/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9896 - val_acc: 0.9045\n",
            "Epoch 436/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.9045\n",
            "Epoch 437/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9906 - val_acc: 0.9034\n",
            "Epoch 438/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9888 - val_acc: 0.9045\n",
            "Epoch 439/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9894 - val_acc: 0.9045\n",
            "Epoch 440/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9894 - val_acc: 0.9034\n",
            "Epoch 441/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9891 - val_acc: 0.9045\n",
            "Epoch 442/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9886 - val_acc: 0.9045\n",
            "Epoch 443/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9878 - val_acc: 0.9045\n",
            "Epoch 444/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9882 - val_acc: 0.9045\n",
            "Epoch 445/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9889 - val_acc: 0.9045\n",
            "Epoch 446/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9886 - val_acc: 0.9045\n",
            "Epoch 447/800\n",
            "789/789 [==============================] - 0s 199us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9893 - val_acc: 0.9045\n",
            "Epoch 448/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9894 - val_acc: 0.9034\n",
            "Epoch 449/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9898 - val_acc: 0.9034\n",
            "Epoch 450/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9896 - val_acc: 0.9034\n",
            "Epoch 451/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9908 - val_acc: 0.9034\n",
            "Epoch 452/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9900 - val_acc: 0.9034\n",
            "Epoch 453/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9913 - val_acc: 0.9034\n",
            "Epoch 454/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9902 - val_acc: 0.9034\n",
            "Epoch 455/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9902 - val_acc: 0.9034\n",
            "Epoch 456/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9907 - val_acc: 0.9034\n",
            "Epoch 457/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9897 - val_acc: 0.9034\n",
            "Epoch 458/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9896 - val_acc: 0.9045\n",
            "Epoch 459/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9910 - val_acc: 0.9045\n",
            "Epoch 460/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9903 - val_acc: 0.9034\n",
            "Epoch 461/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9900 - val_acc: 0.9034\n",
            "Epoch 462/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9898 - val_acc: 0.9045\n",
            "Epoch 463/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9894 - val_acc: 0.9045\n",
            "Epoch 464/800\n",
            "789/789 [==============================] - 0s 201us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9901 - val_acc: 0.9045\n",
            "Epoch 465/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9901 - val_acc: 0.9034\n",
            "Epoch 466/800\n",
            "789/789 [==============================] - 0s 204us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9909 - val_acc: 0.9034\n",
            "Epoch 467/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9910 - val_acc: 0.9034\n",
            "Epoch 468/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9927 - val_acc: 0.9034\n",
            "Epoch 469/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9910 - val_acc: 0.9034\n",
            "Epoch 470/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9899 - val_acc: 0.9034\n",
            "Epoch 471/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9909 - val_acc: 0.9034\n",
            "Epoch 472/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9905 - val_acc: 0.9034\n",
            "Epoch 473/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9906 - val_acc: 0.9034\n",
            "Epoch 474/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9907 - val_acc: 0.9034\n",
            "Epoch 475/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9906 - val_acc: 0.9045\n",
            "Epoch 476/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9904 - val_acc: 0.9045\n",
            "Epoch 477/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9914 - val_acc: 0.9045\n",
            "Epoch 478/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9924 - val_acc: 0.9045\n",
            "Epoch 479/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9914 - val_acc: 0.9045\n",
            "Epoch 480/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9902 - val_acc: 0.9045\n",
            "Epoch 481/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9909 - val_acc: 0.9045\n",
            "Epoch 482/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9909 - val_acc: 0.9045\n",
            "Epoch 483/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9906 - val_acc: 0.9034\n",
            "Epoch 484/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9908 - val_acc: 0.9034\n",
            "Epoch 485/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0196e-07 - acc: 1.0000 - val_loss: 0.9899 - val_acc: 0.9045\n",
            "Epoch 486/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9904 - val_acc: 0.9045\n",
            "Epoch 487/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9903 - val_acc: 0.9045\n",
            "Epoch 488/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9906 - val_acc: 0.9045\n",
            "Epoch 489/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9902 - val_acc: 0.9045\n",
            "Epoch 490/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9907 - val_acc: 0.9045\n",
            "Epoch 491/800\n",
            "789/789 [==============================] - 0s 222us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9901 - val_acc: 0.9045\n",
            "Epoch 492/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9905 - val_acc: 0.9045\n",
            "Epoch 493/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9909 - val_acc: 0.9045\n",
            "Epoch 494/800\n",
            "789/789 [==============================] - 0s 198us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9913 - val_acc: 0.9045\n",
            "Epoch 495/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9919 - val_acc: 0.9045\n",
            "Epoch 496/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9916 - val_acc: 0.9045\n",
            "Epoch 497/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9903 - val_acc: 0.9045\n",
            "Epoch 498/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9907 - val_acc: 0.9045\n",
            "Epoch 499/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9908 - val_acc: 0.9045\n",
            "Epoch 500/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9903 - val_acc: 0.9045\n",
            "Epoch 501/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9915 - val_acc: 0.9045\n",
            "Epoch 502/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9910 - val_acc: 0.9045\n",
            "Epoch 503/800\n",
            "789/789 [==============================] - 0s 235us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9913 - val_acc: 0.9045\n",
            "Epoch 504/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9917 - val_acc: 0.9045\n",
            "Epoch 505/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9914 - val_acc: 0.9045\n",
            "Epoch 506/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9919 - val_acc: 0.9045\n",
            "Epoch 507/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9922 - val_acc: 0.9045\n",
            "Epoch 508/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9923 - val_acc: 0.9045\n",
            "Epoch 509/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9925 - val_acc: 0.9045\n",
            "Epoch 510/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9926 - val_acc: 0.9045\n",
            "Epoch 511/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9917 - val_acc: 0.9045\n",
            "Epoch 512/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9913 - val_acc: 0.9045\n",
            "Epoch 513/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9921 - val_acc: 0.9045\n",
            "Epoch 514/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9918 - val_acc: 0.9045\n",
            "Epoch 515/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9925 - val_acc: 0.9045\n",
            "Epoch 516/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9931 - val_acc: 0.9034\n",
            "Epoch 517/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9925 - val_acc: 0.9045\n",
            "Epoch 518/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9919 - val_acc: 0.9045\n",
            "Epoch 519/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9925 - val_acc: 0.9045\n",
            "Epoch 520/800\n",
            "789/789 [==============================] - 0s 198us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9922 - val_acc: 0.9045\n",
            "Epoch 521/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0195e-07 - acc: 1.0000 - val_loss: 0.9921 - val_acc: 0.9045\n",
            "Epoch 522/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9924 - val_acc: 0.9045\n",
            "Epoch 523/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9917 - val_acc: 0.9045\n",
            "Epoch 524/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9925 - val_acc: 0.9045\n",
            "Epoch 525/800\n",
            "789/789 [==============================] - 0s 199us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9924 - val_acc: 0.9045\n",
            "Epoch 526/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9917 - val_acc: 0.9045\n",
            "Epoch 527/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9921 - val_acc: 0.9045\n",
            "Epoch 528/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9913 - val_acc: 0.9034\n",
            "Epoch 529/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9923 - val_acc: 0.9034\n",
            "Epoch 530/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9927 - val_acc: 0.9034\n",
            "Epoch 531/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9923 - val_acc: 0.9034\n",
            "Epoch 532/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9935 - val_acc: 0.9034\n",
            "Epoch 533/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 534/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 535/800\n",
            "789/789 [==============================] - 0s 204us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9034\n",
            "Epoch 536/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9922 - val_acc: 0.9045\n",
            "Epoch 537/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9922 - val_acc: 0.9045\n",
            "Epoch 538/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9924 - val_acc: 0.9045\n",
            "Epoch 539/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9932 - val_acc: 0.9045\n",
            "Epoch 540/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9931 - val_acc: 0.9045\n",
            "Epoch 541/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9930 - val_acc: 0.9034\n",
            "Epoch 542/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9034\n",
            "Epoch 543/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.9034\n",
            "Epoch 544/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.9045\n",
            "Epoch 545/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9045\n",
            "Epoch 546/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9045\n",
            "Epoch 547/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9045\n",
            "Epoch 548/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9944 - val_acc: 0.9034\n",
            "Epoch 549/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.9034\n",
            "Epoch 550/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.9034\n",
            "Epoch 551/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 552/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 553/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9929 - val_acc: 0.9034\n",
            "Epoch 554/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.9034\n",
            "Epoch 555/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 556/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9034\n",
            "Epoch 557/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9933 - val_acc: 0.9034\n",
            "Epoch 558/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 559/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9930 - val_acc: 0.9034\n",
            "Epoch 560/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9931 - val_acc: 0.9034\n",
            "Epoch 561/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.9034\n",
            "Epoch 562/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9034\n",
            "Epoch 563/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.9045\n",
            "Epoch 564/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9933 - val_acc: 0.9034\n",
            "Epoch 565/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9938 - val_acc: 0.9034\n",
            "Epoch 566/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9935 - val_acc: 0.9034\n",
            "Epoch 567/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9926 - val_acc: 0.9034\n",
            "Epoch 568/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.9034\n",
            "Epoch 569/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9926 - val_acc: 0.9034\n",
            "Epoch 570/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9927 - val_acc: 0.9034\n",
            "Epoch 571/800\n",
            "789/789 [==============================] - 0s 198us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9930 - val_acc: 0.9034\n",
            "Epoch 572/800\n",
            "789/789 [==============================] - 0s 199us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9933 - val_acc: 0.9034\n",
            "Epoch 573/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 574/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 575/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.9045\n",
            "Epoch 576/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 577/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 578/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 579/800\n",
            "789/789 [==============================] - 0s 201us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 580/800\n",
            "789/789 [==============================] - 0s 235us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 581/800\n",
            "789/789 [==============================] - 0s 215us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 582/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 583/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.9034\n",
            "Epoch 584/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 585/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 586/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.9034\n",
            "Epoch 587/800\n",
            "789/789 [==============================] - 0s 200us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 588/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 589/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 590/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 591/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9953 - val_acc: 0.9034\n",
            "Epoch 592/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.9034\n",
            "Epoch 593/800\n",
            "789/789 [==============================] - 0s 199us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 594/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 595/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 596/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9935 - val_acc: 0.9034\n",
            "Epoch 597/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9034\n",
            "Epoch 598/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9045\n",
            "Epoch 599/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9931 - val_acc: 0.9045\n",
            "Epoch 600/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9928 - val_acc: 0.9045\n",
            "Epoch 601/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9929 - val_acc: 0.9034\n",
            "Epoch 602/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.9034\n",
            "Epoch 603/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9921 - val_acc: 0.9034\n",
            "Epoch 604/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9930 - val_acc: 0.9034\n",
            "Epoch 605/800\n",
            "789/789 [==============================] - 0s 169us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9926 - val_acc: 0.9034\n",
            "Epoch 606/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9932 - val_acc: 0.9034\n",
            "Epoch 607/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9933 - val_acc: 0.9034\n",
            "Epoch 608/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9937 - val_acc: 0.9034\n",
            "Epoch 609/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9935 - val_acc: 0.9034\n",
            "Epoch 610/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.9034\n",
            "Epoch 611/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.9034\n",
            "Epoch 612/800\n",
            "789/789 [==============================] - 0s 170us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9938 - val_acc: 0.9034\n",
            "Epoch 613/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9938 - val_acc: 0.9034\n",
            "Epoch 614/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 615/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 616/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.9034\n",
            "Epoch 617/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 618/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 619/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 620/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9944 - val_acc: 0.9034\n",
            "Epoch 621/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.9034\n",
            "Epoch 622/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9944 - val_acc: 0.9034\n",
            "Epoch 623/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 624/800\n",
            "789/789 [==============================] - 0s 169us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 625/800\n",
            "789/789 [==============================] - 0s 168us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 626/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9034\n",
            "Epoch 627/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9930 - val_acc: 0.9034\n",
            "Epoch 628/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 629/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 630/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9953 - val_acc: 0.9034\n",
            "Epoch 631/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.9034\n",
            "Epoch 632/800\n",
            "789/789 [==============================] - 0s 170us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.9034\n",
            "Epoch 633/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 634/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 635/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 636/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 637/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.9034\n",
            "Epoch 638/800\n",
            "789/789 [==============================] - 0s 173us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9944 - val_acc: 0.9034\n",
            "Epoch 639/800\n",
            "789/789 [==============================] - 0s 167us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9034\n",
            "Epoch 640/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 641/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 642/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 643/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 644/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.9034\n",
            "Epoch 645/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 646/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.9034\n",
            "Epoch 647/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 648/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.9034\n",
            "Epoch 649/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 650/800\n",
            "789/789 [==============================] - 0s 201us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 651/800\n",
            "789/789 [==============================] - 0s 199us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 652/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.9034\n",
            "Epoch 653/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 654/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 655/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 656/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.9034\n",
            "Epoch 657/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.9034\n",
            "Epoch 658/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 659/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 660/800\n",
            "789/789 [==============================] - 0s 239us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 661/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 662/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9932 - val_acc: 0.9034\n",
            "Epoch 663/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 664/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 665/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.9034\n",
            "Epoch 666/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 667/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9930 - val_acc: 0.9034\n",
            "Epoch 668/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 669/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 670/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 671/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9938 - val_acc: 0.9034\n",
            "Epoch 672/800\n",
            "789/789 [==============================] - 0s 227us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 673/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 674/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 675/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 676/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 677/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9952 - val_acc: 0.9034\n",
            "Epoch 678/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.9034\n",
            "Epoch 679/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.9034\n",
            "Epoch 680/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9952 - val_acc: 0.9034\n",
            "Epoch 681/800\n",
            "789/789 [==============================] - 0s 203us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.9034\n",
            "Epoch 682/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 683/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 684/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9940 - val_acc: 0.9034\n",
            "Epoch 685/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 686/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 687/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9953 - val_acc: 0.9034\n",
            "Epoch 688/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 689/800\n",
            "789/789 [==============================] - 0s 191us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 690/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 691/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9045\n",
            "Epoch 692/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 693/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 694/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 695/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 696/800\n",
            "789/789 [==============================] - 0s 178us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 697/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.9034\n",
            "Epoch 698/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 699/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 700/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 701/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.9034\n",
            "Epoch 702/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 703/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9935 - val_acc: 0.9034\n",
            "Epoch 704/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 705/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9939 - val_acc: 0.9034\n",
            "Epoch 706/800\n",
            "789/789 [==============================] - 0s 171us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 707/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 708/800\n",
            "789/789 [==============================] - 0s 180us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 709/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.9034\n",
            "Epoch 710/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 711/800\n",
            "789/789 [==============================] - 0s 193us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 712/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 713/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0194e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 714/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9945 - val_acc: 0.9034\n",
            "Epoch 715/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 716/800\n",
            "789/789 [==============================] - 0s 203us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.9034\n",
            "Epoch 717/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.9034\n",
            "Epoch 718/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 719/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 720/800\n",
            "789/789 [==============================] - 0s 174us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.9034\n",
            "Epoch 721/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.9034\n",
            "Epoch 722/800\n",
            "789/789 [==============================] - 0s 172us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9958 - val_acc: 0.9034\n",
            "Epoch 723/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9964 - val_acc: 0.9034\n",
            "Epoch 724/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9965 - val_acc: 0.9034\n",
            "Epoch 725/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9963 - val_acc: 0.9034\n",
            "Epoch 726/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.9034\n",
            "Epoch 727/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.9034\n",
            "Epoch 728/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9960 - val_acc: 0.9034\n",
            "Epoch 729/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9958 - val_acc: 0.9034\n",
            "Epoch 730/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 731/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.9034\n",
            "Epoch 732/800\n",
            "789/789 [==============================] - 0s 175us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 733/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.9034\n",
            "Epoch 734/800\n",
            "789/789 [==============================] - 0s 177us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.9034\n",
            "Epoch 735/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9961 - val_acc: 0.9034\n",
            "Epoch 736/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.9034\n",
            "Epoch 737/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9962 - val_acc: 0.9034\n",
            "Epoch 738/800\n",
            "789/789 [==============================] - 0s 179us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9953 - val_acc: 0.9034\n",
            "Epoch 739/800\n",
            "789/789 [==============================] - 0s 183us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9959 - val_acc: 0.9034\n",
            "Epoch 740/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.9034\n",
            "Epoch 741/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.9034\n",
            "Epoch 742/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9962 - val_acc: 0.9034\n",
            "Epoch 743/800\n",
            "789/789 [==============================] - 0s 181us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.9034\n",
            "Epoch 744/800\n",
            "789/789 [==============================] - 0s 206us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9960 - val_acc: 0.9034\n",
            "Epoch 745/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9961 - val_acc: 0.9034\n",
            "Epoch 746/800\n",
            "789/789 [==============================] - 0s 176us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.9034\n",
            "Epoch 747/800\n",
            "789/789 [==============================] - 0s 208us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9959 - val_acc: 0.9034\n",
            "Epoch 748/800\n",
            "789/789 [==============================] - 0s 205us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.9034\n",
            "Epoch 749/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.9034\n",
            "Epoch 750/800\n",
            "789/789 [==============================] - 0s 198us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.9034\n",
            "Epoch 751/800\n",
            "789/789 [==============================] - 0s 206us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 752/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 753/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 754/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 755/800\n",
            "789/789 [==============================] - 0s 211us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9944 - val_acc: 0.9034\n",
            "Epoch 756/800\n",
            "789/789 [==============================] - 0s 225us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 757/800\n",
            "789/789 [==============================] - 0s 215us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.9034\n",
            "Epoch 758/800\n",
            "789/789 [==============================] - 0s 190us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9941 - val_acc: 0.9034\n",
            "Epoch 759/800\n",
            "789/789 [==============================] - 0s 184us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 760/800\n",
            "789/789 [==============================] - 0s 187us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9943 - val_acc: 0.9034\n",
            "Epoch 761/800\n",
            "789/789 [==============================] - 0s 189us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9948 - val_acc: 0.9034\n",
            "Epoch 762/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.9034\n",
            "Epoch 763/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9953 - val_acc: 0.9034\n",
            "Epoch 764/800\n",
            "789/789 [==============================] - 0s 207us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.9034\n",
            "Epoch 765/800\n",
            "789/789 [==============================] - 0s 192us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9952 - val_acc: 0.9034\n",
            "Epoch 766/800\n",
            "789/789 [==============================] - 0s 219us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.9034\n",
            "Epoch 767/800\n",
            "789/789 [==============================] - 0s 206us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 768/800\n",
            "789/789 [==============================] - 0s 195us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9950 - val_acc: 0.9034\n",
            "Epoch 769/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 770/800\n",
            "789/789 [==============================] - 0s 200us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9951 - val_acc: 0.9034\n",
            "Epoch 771/800\n",
            "789/789 [==============================] - 0s 199us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9953 - val_acc: 0.9034\n",
            "Epoch 772/800\n",
            "789/789 [==============================] - 0s 203us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9952 - val_acc: 0.9034\n",
            "Epoch 773/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9958 - val_acc: 0.9034\n",
            "Epoch 774/800\n",
            "789/789 [==============================] - 0s 201us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9952 - val_acc: 0.9034\n",
            "Epoch 775/800\n",
            "789/789 [==============================] - 0s 200us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.9034\n",
            "Epoch 776/800\n",
            "789/789 [==============================] - 0s 197us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9961 - val_acc: 0.9034\n",
            "Epoch 777/800\n",
            "789/789 [==============================] - 0s 206us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 778/800\n",
            "789/789 [==============================] - 0s 201us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 779/800\n",
            "789/789 [==============================] - 0s 196us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.9034\n",
            "Epoch 780/800\n",
            "789/789 [==============================] - 0s 186us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9954 - val_acc: 0.9034\n",
            "Epoch 781/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9953 - val_acc: 0.9034\n",
            "Epoch 782/800\n",
            "789/789 [==============================] - 0s 218us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.9034\n",
            "Epoch 783/800\n",
            "789/789 [==============================] - 0s 203us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9942 - val_acc: 0.9034\n",
            "Epoch 784/800\n",
            "789/789 [==============================] - 0s 202us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.9034\n",
            "Epoch 785/800\n",
            "789/789 [==============================] - 0s 237us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9955 - val_acc: 0.9034\n",
            "Epoch 786/800\n",
            "789/789 [==============================] - 0s 214us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9962 - val_acc: 0.9034\n",
            "Epoch 787/800\n",
            "789/789 [==============================] - 0s 194us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9959 - val_acc: 0.9034\n",
            "Epoch 788/800\n",
            "789/789 [==============================] - 0s 206us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9963 - val_acc: 0.9034\n",
            "Epoch 789/800\n",
            "789/789 [==============================] - 0s 200us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9966 - val_acc: 0.9034\n",
            "Epoch 790/800\n",
            "789/789 [==============================] - 0s 205us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9967 - val_acc: 0.9034\n",
            "Epoch 791/800\n",
            "789/789 [==============================] - 0s 217us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9964 - val_acc: 0.9034\n",
            "Epoch 792/800\n",
            "789/789 [==============================] - 0s 199us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9969 - val_acc: 0.9034\n",
            "Epoch 793/800\n",
            "789/789 [==============================] - 0s 185us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9961 - val_acc: 0.9034\n",
            "Epoch 794/800\n",
            "789/789 [==============================] - 0s 207us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9968 - val_acc: 0.9034\n",
            "Epoch 795/800\n",
            "789/789 [==============================] - 0s 188us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9967 - val_acc: 0.9034\n",
            "Epoch 796/800\n",
            "789/789 [==============================] - 0s 205us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9969 - val_acc: 0.9034\n",
            "Epoch 797/800\n",
            "789/789 [==============================] - 0s 207us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9961 - val_acc: 0.9034\n",
            "Epoch 798/800\n",
            "789/789 [==============================] - 0s 209us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.9034\n",
            "Epoch 799/800\n",
            "789/789 [==============================] - 0s 182us/step - loss: 1.0193e-07 - acc: 1.0000 - val_loss: 0.9965 - val_acc: 0.9034\n",
            "Epoch 800/800\n",
            "789/789 [==============================] - 0s 200us/step - loss: 1.0192e-07 - acc: 1.0000 - val_loss: 0.9966 - val_acc: 0.9034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRoAgJdJwlI7",
        "colab_type": "code",
        "outputId": "4188e92e-ea9d-4840-8acd-96f7e87d6605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpIQCnQRkYRQoIuIJIQCXUQkIf4X+rTPzNVbVOMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0IWqK-nyrH3",
        "colab_type": "code",
        "outputId": "3cf3f01b-4f19-4b75-c3b4-e91586d1dcc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "prediction = model.predict_classes(X_test)\n",
        "print(\"Predicted digit:\", str(prediction))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted digit: [6 1 1 5 2 0 3 5 2 9 0 8 8 2 8 4 0 0 8 4 3 3 4 5 3 4 3 1 2 5 8 2 9 8 8 2 0\n",
            " 3 0 6 3 8 1 4 5 6 7 8 1 1 0 2 0 8 4 1 5 8 7 3 4 5 2 5 7 6 7 7 6 2 4 4 7 1\n",
            " 0 0 2 1 9 4 9 8 6 6 9 9 7 9 6 9 3 7 1 0 8 1 1 8 4 0 6 1 8 7 5 1 0 8 9 6 9\n",
            " 2 3 5 6 4 5 1 7 7 4 6 3 6 1 6 4 2 4 1 0 9 0 5 5 9 1 9 3 8 6 8 0 1 5 2 5 0\n",
            " 8 0 9 5 9 8 2 1 7 2 2 1 9 6 0 5 9 6 7 7 8 4 8 7 5 5 4 4 0 7 5 7 0 0 3 1 4\n",
            " 6 1 1 9 7 5 6 5 4 4 2 9 9 2 1 8 8 7 2 2 2 1 4 8 3 5 9 7 7 9 7 5 0 2 8 3 2\n",
            " 4 5 9 5 7 5 7 4 0 6 7 0 7 2 1 8 8 9 3 0 5 4 5 6 4 0 4 4 2 4 3 7 8 9 3 1 0\n",
            " 6 8 3 2 6 7 1 7 2 9 1 3 8 5 9 2 9 1 9 8 9 2 8 1 0 4 3 4 8 7 9 3 3 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEtsisSBzI9A",
        "colab_type": "code",
        "outputId": "bbd843d5-41a1-4d62-a737-83f5b214d0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "y_valid"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['6', '1', '1', '8', '2', '9', '9', '3', '2', '1', '8', '8', '8',\n",
              "       '6', '6', '9', '5', '0', '8', '4', '4', '3', '4', '5', '7', '5',\n",
              "       '4', '1', '6', '5', '9', '6', '7', '8', '8', '1', '0', '9', '0',\n",
              "       '6', '2', '8', '1', '4', '3', '0', '9', '8', '1', '1', '0', '3',\n",
              "       '0', '8', '2', '1', '5', '9', '7', '8', '4', '8', '3', '7', '7',\n",
              "       '6', '7', '0', '9', '2', '7', '9', '7', '1', '0', '0', '2', '1',\n",
              "       '3', '0', '4', '8', '2', '6', '4', '9', '3', '9', '6', '7', '0',\n",
              "       '7', '4', '0', '6', '4', '1', '4', '6', '0', '7', '0', '8', '7',\n",
              "       '5', '1', '0', '8', '9', '6', '7', '2', '9', '5', '3', '4', '5',\n",
              "       '1', '8', '8', '7', '6', '2', '6', '1', '6', '9', '2', '4', '1',\n",
              "       '0', '4', '0', '5', '8', '9', '1', '7', '9', '8', '6', '8', '0',\n",
              "       '1', '6', '2', '5', '0', '6', '0', '9', '5', '4', '0', '6', '1',\n",
              "       '7', '2', '0', '1', '3', '6', '0', '6', '2', '6', '2', '1', '3',\n",
              "       '4', '3', '7', '0', '5', '2', '1', '0', '7', '5', '7', '0', '0',\n",
              "       '4', '1', '4', '6', '4', '0', '4', '7', '5', '5', '5', '4', '4',\n",
              "       '2', '9', '4', '2', '6', '8', '8', '7', '6', '6', '2', '1', '8',\n",
              "       '8', '2', '4', '7', '4', '9', '5', '7', '5', '5', '3', '8', '3',\n",
              "       '2', '4', '5', '9', '3', '7', '8', '7', '4', '5', '6', '0', '0',\n",
              "       '7', '2', '1', '6', '5', '7', '8', '7', '5', '6', '3', '6', '0',\n",
              "       '0', '4', '4', '2', '7', '3', '7', '8', '9', '9', '7', '1', '6',\n",
              "       '6', '3', '6', '8', '7', '3', '3', '2', '0', '2', '9', '0', '7',\n",
              "       '9', '2', '4', '1', '9', '8', '4', '9', '7', '1', '0', '7', '7',\n",
              "       '4', '7', '7', '7', '8', '2', '8'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzJ0EvBo-KlD",
        "colab_type": "text"
      },
      "source": [
        "Acurácia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjCMV-Gb9-l_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "790d2b07-6a3b-4960-e613-fad6e8280cb0"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(type(score))\n",
        "print('Test score:',score[0])\n",
        "print('Test accuracy:',score[1])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "Test score: 0.920069623725813\n",
            "Test accuracy: 0.9143344676535284\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}